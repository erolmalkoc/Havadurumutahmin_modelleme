{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMP3Y13MKYXPaBm0gqyH4sI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import time\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Check for GPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")\n","\n","# Informer Model\n","class Informer(nn.Module):\n","    def __init__(self, input_dim, embed_dim, num_heads, num_layers, output_length):\n","        super(Informer, self).__init__()\n","        self.encoder = nn.TransformerEncoder(\n","            nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=0.1, batch_first=True),\n","            num_layers=num_layers\n","        )\n","        self.fc = nn.Linear(embed_dim, output_length)\n","        self.embed = nn.Linear(input_dim, embed_dim)\n","\n","    def forward(self, x):\n","        x = self.embed(x)\n","        x = self.encoder(x)\n","        x = x[:, -1, :]  # Use the last time step\n","        return self.fc(x)\n","\n","# Load data\n","data = pd.read_excel('/content/drive/MyDrive/data_set/train/reversed_weather_data.xlsx', index_col=0)\n","\n","# Target and features\n","target = data['temp'].values\n","features = data[['temp', 'dwpt', 'rhum', 'wdir', 'wspd', 'pres']].values\n","\n","# Scale data\n","scaler_features = MinMaxScaler()\n","scaler_target = MinMaxScaler()\n","\n","features = scaler_features.fit_transform(features)\n","target = scaler_target.fit_transform(target.reshape(-1, 1)).flatten()\n","\n","# Hyperparameters\n","input_length = 24 * 7  # 1 week of hourly data\n","output_length = 24  # 1 day of hourly data\n","embed_dim = 128\n","num_heads = 4\n","num_layers = 2\n","batch_size = 32\n","learning_rate = 1e-4\n","epochs = 20\n","patience = 5\n","\n","# Dataset class\n","class MultiFeatureDataset(torch.utils.data.Dataset):\n","    def __init__(self, features, target, input_length, output_length):\n","        self.features = features\n","        self.target = target\n","        self.input_length = input_length\n","        self.output_length = output_length\n","\n","    def __len__(self):\n","        return len(self.target) - self.input_length - self.output_length + 1\n","\n","    def __getitem__(self, idx):\n","        x = self.features[idx:idx + self.input_length]\n","        y = self.target[idx + self.input_length:idx + self.input_length + self.output_length]\n","        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n","\n","# Dataset and DataLoader\n","dataset = MultiFeatureDataset(features, target, input_length, output_length)\n","train_size = int(0.8 * len(dataset))\n","test_size = len(dataset) - train_size\n","train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","# Model, loss, optimizer\n","model = Informer(\n","    input_dim=features.shape[1],\n","    embed_dim=embed_dim,\n","    num_heads=num_heads,\n","    num_layers=num_layers,\n","    output_length=output_length\n",").to(device)\n","\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n","\n","# Training loop with early stopping\n","best_loss = float('inf')\n","stopping_counter = 0\n","train_losses, val_losses = [], []\n","training_start_time = time.time()\n","\n","for epoch in range(epochs):\n","    model.train()\n","    train_loss = 0\n","    for x_batch, y_batch in train_loader:\n","        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","        optimizer.zero_grad()\n","        preds = model(x_batch)\n","        loss = criterion(preds, y_batch)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","\n","    train_loss /= len(train_loader)\n","    train_losses.append(train_loss)\n","\n","    # Validation loss\n","    model.eval()\n","    val_loss = 0\n","    with torch.no_grad():\n","        for x_batch, y_batch in test_loader:\n","            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","            preds = model(x_batch)\n","            loss = criterion(preds, y_batch)\n","            val_loss += loss.item()\n","\n","    val_loss /= len(test_loader)\n","    val_losses.append(val_loss)\n","\n","    print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n","\n","    # Early stopping logic\n","    if val_loss < best_loss:\n","        best_loss = val_loss\n","        stopping_counter = 0\n","        torch.save(model.state_dict(), '/content/drive/MyDrive/informer_best_model.pth')\n","    else:\n","        stopping_counter += 1\n","        if stopping_counter >= patience:\n","            print(f\"Early stopping triggered at epoch {epoch + 1}\")\n","            break\n","\n","training_end_time = time.time()\n","training_duration = training_end_time - training_start_time\n","\n","# Plot training and validation loss\n","plt.figure(figsize=(10, 6))\n","plt.plot(train_losses, label='Train Loss', color='blue', linewidth=2)\n","plt.plot(val_losses, label='Validation Loss', color='orange', linewidth=2)\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.title('Training and Validation Loss')\n","plt.show()\n","\n","# Load best model\n","model.load_state_dict(torch.load('/content/drive/MyDrive/informer_best_model.pth'))\n","model.eval()\n","\n","# Evaluate model with test data\n","predictions, targets = [], []\n","inference_start_time = time.time()\n","\n","with torch.no_grad():\n","    for x_batch, y_batch in test_loader:\n","        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","        preds = model(x_batch)\n","        predictions.append(preds.cpu().numpy())\n","        targets.append(y_batch.cpu().numpy())\n","\n","inference_end_time = time.time()\n","inference_duration = inference_end_time - inference_start_time\n","\n","# Flatten predictions and targets\n","predictions = np.concatenate(predictions, axis=0)\n","targets = np.concatenate(targets, axis=0)\n","\n","# Invert scaling\n","predictions = scaler_target.inverse_transform(predictions)\n","targets = scaler_target.inverse_transform(targets)\n","\n","# Calculate metrics\n","mse = mean_squared_error(targets, predictions)\n","mae = mean_absolute_error(targets, predictions)\n","rmse = np.sqrt(mse)\n","\n","print(f\"MSE: {mse:.4f}\")\n","print(f\"MAE: {mae:.4f}\")\n","print(f\"RMSE: {rmse:.4f}\")\n","print(f\"Training Time: {training_duration:.2f} seconds\")\n","print(f\"Inference Time: {inference_duration:.2f} seconds\")\n","\n","# Predict last week\n","last_week_features = features[-(input_length + output_length):-output_length]\n","real_next_day = target[-output_length:]\n","\n","last_week_features_tensor = torch.tensor(last_week_features, dtype=torch.float32).unsqueeze(0).to(device)\n","\n","with torch.no_grad():\n","    predicted_next_day = model(last_week_features_tensor).cpu().numpy().flatten()\n","\n","predicted_next_day = scaler_target.inverse_transform(predicted_next_day.reshape(-1, 1)).flatten()\n","real_next_day = scaler_target.inverse_transform(real_next_day.reshape(-1, 1)).flatten()\n","\n","# Plot comparison of prediction and actual data\n","plt.figure(figsize=(10, 6))\n","plt.plot(predicted_next_day, label='Predicted Next Day', color='red', marker='o')\n","plt.plot(real_next_day, label='Actual Next Day', color='blue', marker='x')\n","plt.xlabel('Hour')\n","plt.ylabel('Temperature')\n","plt.title('Predicted vs Actual Temperature for the Next Day')\n","plt.legend()\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rOkb5Bt8LXC8","outputId":"fd31cc40-5896-4248-d4c7-4033aa0b2e82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Using device: cpu\n"]}]}]}